# Configuration Schema for TranscriberApp

# --- Core Processing Modes & Models ---
mode:
  type: enum
  options: ["fast", "advanced"]
  default: "fast"
  description: "Choose between 'fast' (single LLM summary) or 'advanced' (multiple task-specific LLM analyses)."

whisper_model:
  type: enum
  options: ["tiny", "base", "small", "medium", "large-v2", "large-v3"]
  default: "small"
  description: "Select the FasterWhisper model size. Larger models are more accurate but slower and require more VRAM/RAM."

compute_type:
  type: enum
  options: ["int8", "float16", "int16", "bfloat16", "float32"]
  default: "int8"
  description: "Compute type for Whisper. UI filters based on detected device (e.g., 'int8', 'float32' for MPS/CPU; all for CUDA). 'int8' is often fastest on CPU/MPS."

language:
  type: string
  default: null # YAML null for auto-detect
  description: "Language code for transcription (e.g., 'en', 'nl'). Leave null/empty for automatic detection."

word_timestamps_enabled:
  type: bool
  default: false # Default is OFF as it increases processing time/memory
  description: "Enable generation of word-level timestamps by Whisper (slower, uses more memory)."

# --- Speaker Diarization & Mapping ---
pyannote_pipeline:
  type: string
  default: "pyannote/speaker-diarization-3.1" # Requires HF token and accepting terms
  description: "Name of the Pyannote pipeline model from Hugging Face for speaker diarization."

speaker_name_detection_enabled:
  type: bool
  default: false # Default is OFF due to potential LLM inconsistency
  description: "Enable automatic detection of speaker names using an LLM (experimental)."

speaker_map_path:
  type: string
  default: "speaker_map.yaml" # Relative to project root (Mainly for CLI or fallback)
  description: "Path to YAML file for manual speaker mapping."

# --- File Paths ---
input_audio:
  type: string
  default: "audio/sample.mp3" # Default if none specified via CLI/API
  description: "Default input audio file path (relative to project root). Usually overridden."

intermediate_transcript_path:
  type: string
  default: "transcripts/intermediate_transcript.json" # Relative to project root
  description: "Path to store the raw, diarized transcript JSON before final processing."

# --- LLM Configuration ---
llm_models:
  type: object
  description: "Preferred local Ollama models for each task. Models are tried in order listed until one succeeds."
  properties:
    summary: { type: list, default: ["llama3:8b", "mistral:7b", "phi3:medium"], description: "LLMs for summaries ('fast' & 'advanced')." }
    intent: { type: list, default: ["mistral:7b", "llama3:8b", "phi3:medium"], description: "LLMs for intentions ('advanced')." }
    actions: { type: list, default: ["llama3:8b", "phi3:medium", "mistral:7b"], description: "LLMs for actions/decisions ('advanced')." }
    emotion: { type: list, default: ["phi3:medium", "llama3:8b", "mistral:7b"], description: "LLMs for tone/emotion ('advanced')." }
    questions: { type: list, default: ["llama3:8b", "qwen2:7b", "phi3:medium"], description: "LLMs for questions/concerns ('advanced')." }
    legal: { type: list, default: ["llama3:8b", "phi3:medium", "mistral:7b"], description: "LLMs for legal terms/implications ('advanced')." }
    name_detection: { type: list, default: ["llama3:8b", "mistral:7b"], description: "LLMs for speaker name detection (if enabled)." }
    final: { type: list, default: ["llama3:8b", "phi3:medium"], description: "LLM for final report synthesis ('advanced')." }

extra_context_prompt:
  type: string
  default: ""
  description: "Additional context prompt provided to ALL LLM analysis tasks."

llm_default_timeout:
  type: integer
  default: null # Wait indefinitely for Ollama by default
  description: "Default timeout in seconds for individual Ollama LLM calls (null/0 means wait indefinitely)."

llm_final_analysis_timeout:
  type: integer
  default: null
  description: "Specific timeout in seconds for the 'final' aggregating LLM call (overrides default if set)."

# --- Logging & Database ---
logging_enabled: { type: bool, default: true, description: "Enable logging." }
log_level: { type: enum, options: ["DEBUG", "INFO", "SUCCESS", "WARNING", "ERROR", "CRITICAL"], default: "DEBUG", description: "Minimum log level." }
log_backup_count: { type: integer, default: 7, description: "Number of old log files to keep." }
database_filename: { type: string, default: "llm_training_data.db", description: "SQLite DB filename." }