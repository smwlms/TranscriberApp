# src/pipeline_cli.py
import time
import json
import traceback
from pathlib import Path
from typing import Dict, Any, Optional

# Import job manager and statuses
from src.job_manager import job_manager, STATUS_WAITING_FOR_REVIEW, STATUS_FAILED, STATUS_COMPLETED, STATUS_STOPPED

# Import pipeline parts
from src.pipeline_part1 import run_part1
from src.pipeline_part2 import run_part2

# Import utilities
from src.utils.log import log
from src.utils.pipeline_helpers import check_stop # Import check_stop

def run_full_pipeline_cli(job_id: str, config_overrides: Dict[str, Any]):
    """
    Runs the complete pipeline sequentially specifically for the CLI.
    Calls part 1, determines the speaker map automatically, calls part 2.
    Handles errors and updates JobManager status throughout.

    Args:
        job_id: The unique ID for this job run.
        config_overrides: Config overrides derived from the CLI arguments.
    """
    log(f"CLI Pipeline: Starting full sequential run for job {job_id}", "INFO")
    final_status = STATUS_FAILED # Default assumption

    try:
        # --- Run Part 1 ---
        log(f"CLI Pipeline: Running Part 1 for job {job_id}...", "INFO")
        run_part1(job_id, config_overrides) # Execute directly, not in a separate thread
        log(f"CLI Pipeline: Part 1 finished execution for job {job_id}.", "INFO")

        # --- Check Status After Part 1 ---
        part1_status_data = job_manager.get_status(job_id)
        if not part1_status_data:
            raise RuntimeError("Failed to retrieve job status after Part 1 execution.")

        part1_status = part1_status_data.get("status")
        log(f"CLI Pipeline: Status after Part 1 is '{part1_status}'", "DEBUG")

        # Handle non-success statuses from Part 1
        if part1_status == STATUS_FAILED:
            error_msg = part1_status_data.get('error_message', 'Unknown error in Part 1')
            raise RuntimeError(f"Part 1 failed: {error_msg}")
        elif part1_status == STATUS_STOPPED:
            log(f"CLI Pipeline: Part 1 was stopped for job {job_id}. Halting CLI run.", "WARNING")
            final_status = STATUS_STOPPED
            return # Exit cleanly if stopped
        elif part1_status != STATUS_WAITING_FOR_REVIEW:
             # If Part 1 finished but isn't waiting for review, something unexpected happened
             raise RuntimeError(f"Part 1 finished with unexpected status: {part1_status}")

        # --- Determine Speaker Map for Part 2 (CLI Logic) ---
        # In CLI mode, there's no user review step. We use the map proposed by
        # the name detector (if enabled and successful) or an empty map.
        log(f"CLI Pipeline: Determining speaker map for Part 2 automatically...", "INFO")
        job_config = part1_status_data.get("config", {}) # Fetch the merged config stored by Part 1
        name_detection_enabled = job_config.get("speaker_name_detection_enabled", False)
        review_paths = part1_status_data.get("review_data_paths", {})
        proposed_map_path_str = review_paths.get("proposed_map_path")
        final_speaker_map_for_part2 = {} # Default to an empty map

        if name_detection_enabled and proposed_map_path_str:
            proposed_map_path = Path(proposed_map_path_str)
            if proposed_map_path.is_file():
                try:
                    with open(proposed_map_path, "r", encoding='utf-8') as f:
                        # Load the proposed map generated by Part 1
                        final_speaker_map_for_part2 = json.load(f)
                    log(f"CLI Pipeline: Using proposed speaker map from file: {proposed_map_path.name}", "INFO")
                except Exception as e:
                    log(f"CLI Pipeline: Failed to load proposed map '{proposed_map_path.name}', using empty map instead. Error: {e}", "WARNING")
                    final_speaker_map_for_part2 = {}
            else:
                 log(f"CLI Pipeline: Proposed map file not found ('{proposed_map_path.name}'), using empty map.", "WARNING")
                 final_speaker_map_for_part2 = {}
        else:
            # Condition when name detection is off or failed to produce a map file
            log(f"CLI Pipeline: Name detection disabled or no proposed map available, using empty map for Part 2.", "INFO")
            final_speaker_map_for_part2 = {}

        # --- Run Part 2 ---
        log(f"CLI Pipeline: Running Part 2 for job {job_id} with map: {final_speaker_map_for_part2}", "INFO")
        run_part2(job_id, final_speaker_map_for_part2) # Execute directly
        log(f"CLI Pipeline: Part 2 finished execution for job {job_id}.", "INFO")

        # --- Check Final Status After Part 2 ---
        final_status_data = job_manager.get_status(job_id)
        if not final_status_data:
             raise RuntimeError("Failed to retrieve final job status after Part 2 execution.")

        final_status = final_status_data.get("status")
        log(f"CLI Pipeline: Final reported job status is '{final_status}'", "INFO")

        # Ensure the final status reflects completion, otherwise raise error
        if final_status != STATUS_COMPLETED:
             error_msg = final_status_data.get('error_message', f'Part 2 finished with status {final_status}')
             raise RuntimeError(f"Part 2 did not complete successfully: {error_msg}")

    except InterruptedError as e:
        # This catches stop requests raised by check_stop within run_part1 or run_part2
        log(f"CLI Pipeline: Run interrupted by user stop request for job {job_id}: {e}", "WARNING")
        # The status (STOPPED) should already be set by the pipeline part where the stop occurred.
        final_status = STATUS_STOPPED

    except Exception as e:
        # Catch any other unexpected errors during the CLI orchestration
        error_msg = f"CLI Pipeline Orchestration Error for job {job_id}: {e}"
        log(error_msg, "CRITICAL")
        log(traceback.format_exc(), "ERROR")
        # Attempt to update the job status to FAILED if it's not already terminal
        current_status_data = job_manager.get_status(job_id)
        if current_status_data and current_status_data.get("status") not in [STATUS_FAILED, STATUS_STOPPED]:
            job_manager.set_error(job_id, f"Critical error during CLI run: {e}")
        final_status = STATUS_FAILED # Ensure status reflects the failure

    # Final log summarizing the outcome of the CLI run
    log(f"CLI Pipeline: Finished full run for job {job_id} with final effective status '{final_status}'.", "INFO")

# --- End of src/pipeline_cli.py ---